{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用训练好的emb来分析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/sgd_deep_learning/sgd_nlp\n"
     ]
    }
   ],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_nlp/\n",
    "import sys \n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgd_nlp.embedding import *\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_HOME = r'./apps/embedding/save/'\n",
    "\n",
    "class glove_context:\n",
    "    corpus_factory= os.path.join(SAVE_HOME, 'glove/corpus_obj.cf')\n",
    "    model_path= os.path.join(SAVE_HOME, 'glove/glove_weights.path')\n",
    "    emb_dim = 300\n",
    "    sparse_emb = False\n",
    "    win_width=11\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "\n",
    "class skip_gram_context:\n",
    "    corpus_factory= os.path.join(SAVE_HOME, 'skipgram/corpus_obj.cf')\n",
    "    model_path= os.path.join(SAVE_HOME, 'skipgram/skipgram_weights.path')\n",
    "    emb_dim = 300\n",
    "    sparse_emb = True\n",
    "    win_width=11\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "class cbow_context:\n",
    "    corpus_factory= os.path.join(SAVE_HOME, 'cbow/corpus_obj.cf')\n",
    "    model_path= os.path.join(SAVE_HOME,'cbow/cbow_weights.path')\n",
    "    emb_dim = 300\n",
    "    sparse_emb = True\n",
    "    win_width=11\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus_factory(obj_file_name):\n",
    "    with open(obj_file_name, 'rb') as fin:\n",
    "        print(\"!!! load corpus factory success !!!\")\n",
    "        return pickle.load(fin)\n",
    "\n",
    "    \n",
    "def load_emb(context):\n",
    "    corpus_factory = load_corpus_factory(context.corpus_factory)\n",
    "    \n",
    "    model = None\n",
    "    if 'skip' in context.model_path:\n",
    "        model = SkipGram(emb_dim=context.emb_dim,\n",
    "                     token_num=corpus_factory.token_num(),\n",
    "                     sparse_emb=context.sparse_emb).to(context.device)\n",
    "    \n",
    "    elif 'cbow' in  context.model_path:\n",
    "        model = Cbow(emb_dim=context.emb_dim,\n",
    "                token_num=corpus_factory.token_num(),\n",
    "                win_width=context.win_width,\n",
    "                sparse_emb=context.sparse_emb).to(context.device)\n",
    "        \n",
    "    elif 'glove' in  context.model_path:\n",
    "        model = Glove(emb_dim=context.emb_dim,\n",
    "                token_num=corpus_factory.token_num(),\n",
    "                sparse_emb=context.sparse_emb).to(context.device)\n",
    "        \n",
    "    model.load_state_dict(torch.load(context.model_path))\n",
    "    print(\"!!! Load model weights success !!!\")\n",
    "    \n",
    "    avg_emb = None\n",
    "    \n",
    "    if 'glove' in context.model_path:\n",
    "        emb_l = model.emb_i.weight\n",
    "        emb_r = model.emb_j.weight\n",
    "        avg_emb = (emb_l+emb_r)/2\n",
    "    \n",
    "    else:\n",
    "        emb_l = model.emb_i.weight\n",
    "        emb_r = model.emb_o.weight\n",
    "        avg_emb = (emb_l+emb_r)/2\n",
    "    \n",
    "    return avg_emb, corpus_factory \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[-9.2314e-01,  2.0012e+00, -1.9468e+00,  ..., -2.2160e-01,\n",
      "         -1.5083e+00,  1.6486e+00],\n",
      "        [ 2.7495e-01, -8.3205e-01,  2.2257e+00,  ...,  7.7470e-01,\n",
      "         -1.0426e+00, -2.7914e+00],\n",
      "        [ 1.5068e+00, -7.9358e-01,  1.1863e+00,  ..., -4.7400e-01,\n",
      "         -6.3848e-01, -8.9149e-01],\n",
      "        ...,\n",
      "        [-9.9248e-01,  6.0319e-02,  9.2521e-01,  ...,  4.8005e-01,\n",
      "          4.0357e-01,  4.3409e-01],\n",
      "        [-2.3199e-01, -4.9969e-01, -3.6279e-01,  ...,  8.7473e-01,\n",
      "         -1.1759e+00, -2.7884e-01],\n",
      "        [-5.3532e-01,  4.0148e-01,  1.0868e+00,  ..., -1.5217e+00,\n",
      "          8.2015e-01,  1.3501e-03]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "avg_emb torch.Size([23707, 300])\n",
      "token_num 23697\n",
      "\n",
      "****** VOCAB LOG INFO ******\n",
      "corpus_word_num: 887249\n",
      "vocab_size: 23697\n",
      "word_freq_count: \n",
      "[('the', 26050), ('you', 24618), ('i', 24456), ('to', 19978), ('and', 19046), ('a', 15636), ('it', 9891), ('is', 9517), ('rachel:', 9312), ('ross:', 9226), ('that', 8881), ('chandler:', 8492), ('monica:', 8423), ('joey:', 8332), ('oh', 7807), ('phoebe:', 7527), ('in', 7509), ('of', 7109), ('what', 7025), ('on', 6210), ('this', 6133), ('me', 5762), ('just', 5745), ('no', 5615), ('so', 5598), ('my', 5541), ('with', 5242), ('her', 5139), ('are', 4963), ('yeah', 4944), ('know', 4915), ('okay', 4900), ('have', 4593), ('for', 4583), ('do', 4573), ('we', 4502), ('not', 4464), ('ross', 4359), ('well', 4351), ('he', 4347), ('all', 4163), ('monica', 4128), ('was', 4085), ('chandler', 4074), ('joey', 4073), ('but', 4034), ('up', 4013), ('at', 3979), ('hey', 3969), ('she', 3931)]...\n",
      "...[('implicit', 1), ('plicit', 1), ('cursory', 1), ('protectors', 1), ('cheeseburgers', 1), ('aches', 1), ('hyperventilating', 1), ('assesses', 1), ('1017-1018', 1), ('vo:', 1), ('stomach-aches', 1), ('stomach-ache', 1), ('dracula', 1), ('unanswerable', 1), ('daa', 1), ('raa', 1), ('head-first', 1), ('umbilical', 1), ('spongy', 1), ('reunited', 1), ('bam-bam-bam-bam', 1), ('girl-baby', 1), ('car-service', 1), (\"ethel's\", 1), (\"'40s\", 1), ('gazette', 1), ('continents', 1), (\"cab's\", 1), ('backseat', 1), ('baby-duck', 1), ('infants', 1), ('feces', 1), ('birdcalls', 1), ('woodsman', 1), ('sci-fi', 1), ('life;', 1), ('time-machine', 1), ('death-cab', 1), ('cop-show', 1), ('high-school', 1), ('32c', 1), ('bra-size', 1), ('36d', 1), ('destination', 1), ('flight-number', 1), ('jfk', 1), ('hearing-aids', 1), ('philanges', 1), (\"friggin'\", 1), ('kitchen-counter', 1)]\n",
      "****** vocab log end ******\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(skip_gram_context)\n",
    "print(type(avg_emb))\n",
    "print(avg_emb)\n",
    "print('avg_emb', avg_emb.shape)\n",
    "print('token_num',corpus_factory.vocab.token_num())\n",
    "print()\n",
    "print(corpus_factory.vocab.log_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 老友记6个人的亲密关系排序\n",
    "\n",
    "``` python\n",
    "['monica', 'phoebe', 'rachel', 'joey', 'chandler', 'ross',]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(emb, corpus_factory):\n",
    "    friends = ['monica', 'phoebe', 'rachel', 'joey', 'chandler', 'ross']\n",
    "    friends_id = corpus_factory.vocab[friends]\n",
    "    \n",
    "    friends_emb = emb[friends_id]\n",
    "    \n",
    "    # 计算6个人间的协方差\n",
    "    cov = friends_emb.mm(friends_emb.transpose(0, 1))    \n",
    "    print('\\n emb向量内积')\n",
    "    print(cov)\n",
    "\n",
    "    sort_id = torch.argsort(cov, dim = 1, descending=True)\n",
    "    \n",
    "    print(\"每个人最亲近的关系排序\")\n",
    "    for i in range(6):\n",
    "       \n",
    "        sortid = sort_id[i].tolist()\n",
    "        print([friends[j] for j in sortid])\n",
    "\n",
    "### 找出每个人最相关的top-20的词\n",
    "def find_topk(emb, corpus_factory ,k=20):\n",
    "    friends = ['monica', 'phoebe', 'rachel', 'joey', 'chandler', 'ross']\n",
    "    friends_id = corpus_factory.vocab[friends]\n",
    "    friends_emb = emb[friends_id]\n",
    "    \n",
    "    cov = friends_emb.mm(emb.transpose(0, 1))   # [6, vocab_token_num]\n",
    "    print('\\n emb向量内积')\n",
    "    print(cov)\n",
    "    sort_id = torch.argsort(cov, dim = 1, descending=True)[:, :20]  # [6, 20]\n",
    "\n",
    "    print(\"每个人关系最紧密的topk-20的词\")\n",
    "    for i in range(6):\n",
    "       \n",
    "        sortid = sort_id[i].tolist()\n",
    "        print([corpus_factory.vocab.to_tokens(sortid)])\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "\n",
      " emb向量内积\n",
      "tensor([[ 3.9516e+02,  3.1970e+01,  1.7339e+01,  4.8221e-01,  4.1077e+01,\n",
      "          1.1537e+00],\n",
      "        [ 3.1970e+01,  4.0726e+02, -7.8354e+00, -1.5132e+01, -3.7384e+01,\n",
      "          2.9914e+01],\n",
      "        [ 1.7339e+01, -7.8354e+00,  4.5861e+02,  6.2885e+01,  3.0006e+01,\n",
      "         -3.7074e+01],\n",
      "        [ 4.8221e-01, -1.5132e+01,  6.2885e+01,  5.1977e+02,  3.3129e+01,\n",
      "          2.1989e+01],\n",
      "        [ 4.1077e+01, -3.7384e+01,  3.0006e+01,  3.3129e+01,  4.1682e+02,\n",
      "          4.7946e+01],\n",
      "        [ 1.1537e+00,  2.9914e+01, -3.7074e+01,  2.1989e+01,  4.7946e+01,\n",
      "          4.1671e+02]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "每个人最亲近的关系排序\n",
      "['monica', 'chandler', 'phoebe', 'rachel', 'ross', 'joey']\n",
      "['phoebe', 'monica', 'ross', 'rachel', 'joey', 'chandler']\n",
      "['rachel', 'joey', 'chandler', 'monica', 'phoebe', 'ross']\n",
      "['joey', 'rachel', 'chandler', 'ross', 'monica', 'phoebe']\n",
      "['chandler', 'ross', 'monica', 'joey', 'rachel', 'phoebe']\n",
      "['ross', 'chandler', 'phoebe', 'joey', 'monica', 'rachel']\n",
      "\n",
      " emb向量内积\n",
      "tensor([[  3.1149, -37.7564, -20.6960,  ...,  22.7340, -15.4829,  15.6478],\n",
      "        [-27.6951,  24.1338,  45.4347,  ...,   6.2979,   0.4219,  15.8579],\n",
      "        [ 11.3419,  -5.1316, -21.0374,  ...,  19.2215, -13.8882,  -2.8207],\n",
      "        [  2.4049, -14.8012, -21.9629,  ...,  -2.5845,  -9.3259, -26.5434],\n",
      "        [-18.8834,  57.8280, -15.2223,  ...,   7.6274, -18.5866,   4.7732],\n",
      "        [-47.6446,  15.2398,  15.2470,  ...,  23.8855,  -4.7749,  -1.7463]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "每个人关系最紧密的topk-20的词\n",
      "[['monica', 'shhhhhh', 'wood>', 'irate', 'sadwich', 'dared', 'coupla', \"victoria's\", 'gaudy', 'waswas', 'from-', 'selection', 'mmmwa', 'vandalism', 'cdnow', 'backdad', 'suspicion', 'loyal', 'ehactually', 'kournikova']]\n",
      "[['phoebe', 'naah', 'zone', 'used', 'monster', 'purred', 'please-please', 'stroke', 'la', 'photo', 'horror', 'savin', 'documentary', 'bask', 'ended', 'field', 'benny', 'shaken', 'nose', 'hallway']]\n",
      "[['rachel', 'charlie:', 'childishly', 'has-has', 'accompanied', 'break-up', 'millennium', 'yeahwe', 'brand', 'purr', 'son-of-a-', \"becausei'm\", 'cello', 'unattainable', 'pleads', \"julie's\", 'suspicion', 'exchanged', 'exiting', 'ages']]\n",
      "[['joey', 'smoothy', 'horseback', 'smudgy', 'mac', 'occurring', 'vegetarians', 'kreeger', 'stockholm', 'genie', 'you:', 'faucet', 'spuds', 'endearment', 'disputed', 'mckenna', 'russell', 'kissey', 'descended', 'children:']]\n",
      "[['chandler', \"'how\", 'halfway', 'non-breasts', \"glacier's\", 'ooo-ooh', 'creaks', '515', 'boys', \"blarrglarrghh'\", 'maniac', 'discussion', 'strides', 'lure', 'writer', 'stat', 'unsure', 'chair', 'shewell', 'likethings']]\n",
      "[['ross', 'bounce', \"sak's\", 'two-two', 'shocking', 'typing', 'proceeds', 'grand', 'met', 'co-worker', 'safely', 'tangle', 'sneeze', 'ipasses', 'enganged', 'headdddd', 'writers', 'suspect', 'talked', 'justill']]\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(skip_gram_context)\n",
    "analysis(avg_emb, corpus_factory)\n",
    "find_topk(avg_emb, corpus_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "\n",
      " emb向量内积\n",
      "tensor([[12.4432,  2.1130,  3.0443,  2.3352,  3.1008,  0.8121],\n",
      "        [ 2.1130, 16.7685,  2.9680,  1.5070,  1.4071,  0.8910],\n",
      "        [ 3.0443,  2.9680, 11.7208,  2.0097,  1.6701,  1.6479],\n",
      "        [ 2.3352,  1.5070,  2.0097, 12.6702,  3.6263,  1.6323],\n",
      "        [ 3.1008,  1.4071,  1.6701,  3.6263, 10.4537,  1.7439],\n",
      "        [ 0.8121,  0.8910,  1.6479,  1.6323,  1.7439,  8.2177]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "每个人最亲近的关系排序\n",
      "['monica', 'chandler', 'rachel', 'joey', 'phoebe', 'ross']\n",
      "['phoebe', 'rachel', 'monica', 'joey', 'chandler', 'ross']\n",
      "['rachel', 'monica', 'phoebe', 'joey', 'chandler', 'ross']\n",
      "['joey', 'chandler', 'monica', 'rachel', 'ross', 'phoebe']\n",
      "['chandler', 'joey', 'monica', 'ross', 'rachel', 'phoebe']\n",
      "['ross', 'chandler', 'rachel', 'joey', 'phoebe', 'monica']\n",
      "\n",
      " emb向量内积\n",
      "tensor([[-0.9886,  0.4517,  0.7783,  ...,  0.7079, -2.0263,  2.0932],\n",
      "        [-4.7495, -0.1710,  0.3887,  ..., -0.0084, -3.4190, -1.4242],\n",
      "        [-2.2462,  0.2953,  0.2433,  ...,  0.0815, -2.3517,  1.4521],\n",
      "        [-1.3363,  0.3165,  0.6335,  ..., -1.9516, -0.6662,  0.1077],\n",
      "        [-3.1436,  0.9222,  0.4389,  ..., -0.5316, -3.4656, -0.5743],\n",
      "        [-2.4684,  0.5427,  0.3218,  ..., -2.5510, -5.0825,  1.6486]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "每个人关系最紧密的topk-20的词\n",
      "[['monica', 'resembling', 'authority', 'brooklyn', 'you-you--i', 'gasp', 'mimicking', 'sneezes', \"howard's\", 'smiling', 'erm', 'miming', 'hallway', 'wait-wait', 'si', 'agrees', 'ruined', 'memorable', 'frannie', 'menstruating']]\n",
      "[['phoebe', 'buffay', 'quack', 'rushes', 'shhhh', 'packing', 'sr:', 'arrive', 'giggles', 'ewwww', 'treeger:', 'phoebe;', 'receive', 'growl', 'drags', 'devastating', \"monican't\", 'startled', 'resist', 'you-see-what-i-mean']]\n",
      "[['rachel', 'spa', 'slowly', 'throws', 'meeting', 'hugs', 'whatbut', 'sulking', 'closing', 'persecuting', 'arguing', 'climbs', 'rips', 'happily', '<amy', 'funk', 'samantha', 'painting', \"what'm\", 'la']]\n",
      "[['joey', 'horror', 'approaching', 'customer', 'of-of', 'boob', 'buzzer', 'attendant', 'thud', 'sarcastic', 'raymond', 'fajitas', 'tux', 'tribbiani', 'returning', 'janines', 'lydia', 'ooooohh', 'sprouts', 'wha-a']]\n",
      "[['chandler', 'blowing', 'pete', 'nods:', 'angrily', 'dumbfounded', 'bing', 'draddle', 'nervouslytzz-zzz', 'sandwich', 'flirt', 'yo', 'lifetime', 'treeger', 'bathing', 'approaching', 'hugs', 'shut', 'velvet', 'wakes']]\n",
      "[['ross', 'continues', 'susan', 'carol', 'buzz', 'lip', 'punches', 'stepping', 'enter', \"charlie's\", 'cheryl:', 'embarrassing', 'cleansing', 'mouths', 'blanket', 'brush', 'sofa', 'expecting', 'barbados', 'apologise']]\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(cbow_context)\n",
    "analysis(avg_emb, corpus_factory)\n",
    "find_topk(avg_emb, corpus_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "\n",
      " emb向量内积\n",
      "tensor([[ 1.0646e+00,  1.3017e-02, -2.3883e-03,  1.1614e-01, -4.0152e-03,\n",
      "          7.0150e-02],\n",
      "        [ 1.3017e-02,  4.7444e+00,  3.7048e-01,  2.7121e-01, -3.4167e-02,\n",
      "          2.2401e-01],\n",
      "        [-2.3883e-03,  3.7048e-01,  1.0681e+00,  1.0799e-02, -3.5361e-02,\n",
      "          4.9005e-02],\n",
      "        [ 1.1614e-01,  2.7121e-01,  1.0799e-02,  6.5963e-01, -3.0109e-03,\n",
      "          4.9508e-02],\n",
      "        [-4.0152e-03, -3.4167e-02, -3.5361e-02, -3.0109e-03,  3.5225e-01,\n",
      "          6.5839e-02],\n",
      "        [ 7.0150e-02,  2.2401e-01,  4.9005e-02,  4.9508e-02,  6.5839e-02,\n",
      "          3.4042e-01]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "每个人最亲近的关系排序\n",
      "['monica', 'joey', 'ross', 'phoebe', 'rachel', 'chandler']\n",
      "['phoebe', 'rachel', 'joey', 'ross', 'monica', 'chandler']\n",
      "['rachel', 'phoebe', 'ross', 'joey', 'monica', 'chandler']\n",
      "['joey', 'phoebe', 'monica', 'ross', 'rachel', 'chandler']\n",
      "['chandler', 'ross', 'joey', 'monica', 'phoebe', 'rachel']\n",
      "['ross', 'phoebe', 'monica', 'chandler', 'joey', 'rachel']\n",
      "\n",
      " emb向量内积\n",
      "tensor([[-0.9426,  0.0038,  0.0084,  ...,  0.2289,  0.6141, -0.6476],\n",
      "        [ 1.0895,  0.0146,  0.0099,  ...,  0.2243,  2.1052, -0.3774],\n",
      "        [ 0.2811,  0.0086,  0.0099,  ...,  0.1453,  1.0313, -0.0125],\n",
      "        [ 0.0202,  0.0045,  0.0073,  ...,  0.0979,  0.4079, -0.8139],\n",
      "        [ 0.6194,  0.0052,  0.0052,  ..., -0.2243,  0.0616,  0.2447],\n",
      "        [-0.0040,  0.0053,  0.0062,  ...,  0.1456,  0.2556, -0.2213]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "每个人关系最紧密的topk-20的词\n",
      "[['crumbly', 'imhere', 're-testing', 'belive', 'an-an-anyway', 'hovercrafts', 'uff', 'dodged', 'impaired', 'bah-bah-bha-bhan', 'helpers', 'two-piece', 'recipe', 'clich', \"'monica\", 'thud', 'oooohhh', 'drain', 'jinkies', 'snowing']]\n",
      "[['insinuating', 'relaxes', \"thirty's\", 'strictly', 'superiors', '150', 'adam', 'unpack', 'yeahwe', 'woodford', 'statue', 'videotaped', 'bird', 'vascular', 'wha-', 'aunts', 'october', 'phoebe', \"no-one's\", 'minser']]\n",
      "[['ya-huh', 'geologists', 'keyboards', 'casinos', \"it's-\", 'potter', 'shesgoing', 'farrell', '<forgetting', 'frannie:', \"b'cause\", 'omelet', 'jinx', 'troopers', 'chanterelles', 'ane', 'net', 'mandy', 'wallets', 'red-haired']]\n",
      "[['sister-in-laws', \"yougin's\", 'mckenna:', 'nibbly', 'la-la-la-laohhh', \"franz's\", 'mh', 'let-let', '<amy', 'pounce', 'photoshop', 'grim', 'belive', 'karat', 'viejo', 'neds', 'discredited', 'clasp', 'thinkohthat', 'eveyone']]\n",
      "[['potassium', 'gloatingly', 'sorryhe', 'blah-blah-blah-blah-blah', 'pushover', 'bedspread', 'wh-where', 'girlfriendwhich', 'knowim', 'brrrrrrr', 'guarded', 'puma', 'nibbling', 'faded', \"it's-\", '$3', 'arthur', 'hebt', 'un-floopy', 'moss']]\n",
      "[['traumatic', 'box:', 'och', 'smirking', 'cellphone', 'half-charred', 'jumpingnow', 'whatsoever', \"can't-\", 'unload', 'brushes', 'shredder', \"meani'm\", 'rhymed', 'persue', 'varsity', 'vip', 'letsits', 'monkey;', 'teen']]\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(glove_context)\n",
    "analysis(avg_emb, corpus_factory)\n",
    "find_topk(avg_emb, corpus_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "[结果分析.txt](./%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea68e26e2ec5512da56afdae1ccbc3f0c30917ed34c855b0cd4787221c3f6afe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
