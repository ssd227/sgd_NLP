{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/sgd_deep_learning/sgd_nlp\n"
     ]
    }
   ],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_nlp/\n",
    "import sys \n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sgd_nlp.embedding import Glove, CorpusFactoryGlove"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(config):\n",
    "    if config.load_corpus_obj and os.path.isfile(config.corpus_obj_path):\n",
    "        with open(config.corpus_obj_path, 'rb') as fin:\n",
    "            print(\"!!! load corpus factory success !!!\")\n",
    "            return pickle.load(fin)\n",
    "    else:\n",
    "        # corpus files path\n",
    "        print('CURRENT PATH:\\t', config.corpus_dir_path)\n",
    "\n",
    "        # new obj from origin corpus file path\n",
    "        corpus_factory = CorpusFactoryGlove(config.corpus_dir_path,\n",
    "                                            win_width=config.win_width,\n",
    "                                            pair_symmetric=config.pair_symmetric)\n",
    "        corpus_factory.vocab.log_info()  # show log\n",
    "\n",
    "        with open(config.corpus_obj_path, 'wb') as fout:\n",
    "            pickle.dump(corpus_factory, fout)\n",
    "\n",
    "        return corpus_factory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(corpus_factory, model, optimizer, scheduler, config):\n",
    "    # train setting\n",
    "    all_words_num = corpus_factory.word_pairs_num()  # 文档中的总词数\n",
    "    epoch = int(config.corpus_run_loop * all_words_num / config.batch_size)  # 总共需要迭代几个epoch\n",
    "    global_min_loss = 1e10\n",
    "\n",
    "    # training loop\n",
    "    for i in range(epoch):\n",
    "        t1 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        batch_data = corpus_factory.training_batch(config.batch_size, device=config.device)\n",
    "        y = model.forward(batch_data)\n",
    "\n",
    "        # objective function (loss function)\n",
    "        j = torch.mean(y)  # minimize objective\n",
    "\n",
    "        # backward and update weight\n",
    "        j.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if epoch % config.scheduler_step == 0:\n",
    "        #     scheduler.step()\n",
    "\n",
    "        # output info\n",
    "        tmp_t = time.time() - t1\n",
    "        if i % config.log_step == 0:\n",
    "            print('epoch:{}/{}, loss:{}, csot_time: {}'.format(i, epoch, j, tmp_t))\n",
    "\n",
    "        # save best model\n",
    "        if j < global_min_loss:\n",
    "            global_min_loss = j\n",
    "            torch.save(model.state_dict(), config.model_weights_obj_path)\n",
    "            print('new bset loss: {}'.format(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # 文本语料路径\n",
    "    data_home = r'./data'\n",
    "    sub_dir = r'friends/season10'\n",
    "    corpus_dir_path = os.path.join(data_home, sub_dir)\n",
    "    \n",
    "    # 直接加载对象\n",
    "    SAVE_HOME = r'./apps/embedding/save/'\n",
    "    model_name = r'glove'\n",
    "    \n",
    "    load_corpus_obj = True # 训练前修改！\n",
    "    corpus_obj_path = os.path.join(SAVE_HOME, model_name, r'corpus_obj.cf') # 加载预处理语料  default:None\n",
    "     \n",
    "    load_model_weight_obj = True # 训练前修改！\n",
    "    model_weights_obj_path = os.path.join(SAVE_HOME, model_name, r'glove_weights.path') # 加载预训练模型参数 default:None\n",
    "    \n",
    "    # 语料预处理参数\n",
    "    win_width = 10  # context 窗口大小\n",
    "    pair_symmetric = True\n",
    "  \n",
    "    \n",
    "    # 模型参数\n",
    "    device = torch.device('cuda')\n",
    "    emb_dim = 300\n",
    "    sparse_emb = False\n",
    "    \n",
    "    # 训练参数\n",
    "    lr = 1e-2 # 初始学习率\n",
    "    corpus_run_loop = 10  # 看n遍文本\n",
    "    batch_size = 1024   # 每个batch的大小\n",
    "    scheduler_step = 100\n",
    "    log_step = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "epoch:0/14708, loss:0.45056708188466177, csot_time: 0.01168513298034668\n",
      "new bset loss: 0.45056708188466177\n",
      "new bset loss: 0.34416452005027226\n",
      "new bset loss: 0.32712092037998153\n",
      "new bset loss: 0.3226029156847734\n",
      "new bset loss: 0.32169612111348805\n",
      "new bset loss: 0.3047192806519861\n",
      "new bset loss: 0.29708835836208775\n",
      "epoch:500/14708, loss:0.48392802933632617, csot_time: 0.004575014114379883\n",
      "epoch:1000/14708, loss:0.3644226818461068, csot_time: 0.0046062469482421875\n",
      "new bset loss: 0.28362923298549564\n",
      "epoch:1500/14708, loss:0.45654477333453786, csot_time: 0.004652500152587891\n",
      "new bset loss: 0.24977882111505798\n",
      "new bset loss: 0.24550845171336855\n",
      "epoch:2000/14708, loss:0.32347228072811174, csot_time: 0.005177974700927734\n",
      "new bset loss: 0.23148263134084396\n",
      "epoch:2500/14708, loss:0.31313353024114043, csot_time: 0.004429340362548828\n",
      "epoch:3000/14708, loss:0.4088120956819198, csot_time: 0.005589723587036133\n",
      "epoch:3500/14708, loss:0.3622856548736219, csot_time: 0.004613399505615234\n",
      "epoch:4000/14708, loss:0.4425695223228113, csot_time: 0.0046041011810302734\n",
      "epoch:4500/14708, loss:0.3311965229481896, csot_time: 0.004437923431396484\n",
      "epoch:5000/14708, loss:0.31471522761020976, csot_time: 0.004689931869506836\n",
      "epoch:5500/14708, loss:0.2782654919323633, csot_time: 0.0052013397216796875\n",
      "new bset loss: 0.22697870674600887\n",
      "new bset loss: 0.22445388082784312\n",
      "epoch:6000/14708, loss:0.31650350231910385, csot_time: 0.004508018493652344\n",
      "new bset loss: 0.2033014385019746\n",
      "epoch:6500/14708, loss:0.37810295785668085, csot_time: 0.004248142242431641\n",
      "epoch:7000/14708, loss:0.3306685159660434, csot_time: 0.005098819732666016\n",
      "epoch:7500/14708, loss:0.3502914527344322, csot_time: 0.007846355438232422\n",
      "epoch:8000/14708, loss:0.33652349751022403, csot_time: 0.005159616470336914\n",
      "epoch:8500/14708, loss:0.43997106758377985, csot_time: 0.005839824676513672\n",
      "epoch:9000/14708, loss:0.32967297392433764, csot_time: 0.0044536590576171875\n",
      "new bset loss: 0.19267088553284298\n",
      "epoch:9500/14708, loss:0.3224100300430465, csot_time: 0.004698753356933594\n",
      "epoch:10000/14708, loss:0.28702433291548496, csot_time: 0.00468134880065918\n",
      "epoch:10500/14708, loss:0.34304295379650873, csot_time: 0.004758358001708984\n",
      "epoch:11000/14708, loss:0.2927765170458955, csot_time: 0.004647731781005859\n",
      "epoch:11500/14708, loss:0.31689849449546875, csot_time: 0.004884004592895508\n",
      "epoch:12000/14708, loss:0.25610550388763076, csot_time: 0.004483461380004883\n",
      "epoch:12500/14708, loss:0.24507311094421122, csot_time: 0.004629373550415039\n",
      "epoch:13000/14708, loss:0.3385988544914595, csot_time: 0.006530284881591797\n",
      "epoch:13500/14708, loss:0.3389933461507999, csot_time: 0.0044667720794677734\n",
      "epoch:14000/14708, loss:0.24326531690030306, csot_time: 0.004786968231201172\n",
      "epoch:14500/14708, loss:0.29650245265959196, csot_time: 0.005332231521606445\n"
     ]
    }
   ],
   "source": [
    "def app():\n",
    "    # class obj\n",
    "    corpus_factory = load_corpus(config=config)\n",
    "\n",
    "    model = Glove(emb_dim=config.emb_dim,\n",
    "                  token_num=corpus_factory.token_num(),\n",
    "                  sparse_emb=config.sparse_emb).to(config.device)\n",
    "\n",
    "    # for pa in model.parameters():\n",
    "    #     print(pa)\n",
    "    #     print(pa.device)\n",
    "\n",
    "    # load weight\n",
    "    if config.load_model_weight_obj and os.path.isfile(config.model_weights_obj_path):\n",
    "        model.load_state_dict(torch.load(config.model_weights_obj_path))\n",
    "        print(\"!!! Load model weights success !!!\")\n",
    "\n",
    "    # optimizer = torch.optim.SparseAdam(params=model.parameters(), lr=1e-1)\n",
    "    # optimizer = torch.optim.SGD(params=model.parameters(), lr=1e-1, momentum=0.9)\n",
    "    optimizer = torch.optim.Adagrad(params=model.parameters(), lr=config.lr)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    train(corpus_factory=corpus_factory,\n",
    "          model=model,\n",
    "          optimizer=optimizer,\n",
    "          scheduler=scheduler,\n",
    "          config=config)\n",
    "\n",
    "app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
