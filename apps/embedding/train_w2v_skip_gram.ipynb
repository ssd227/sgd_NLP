{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec (skip gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/sgd_deep_learning/sgd_nlp\n"
     ]
    }
   ],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_nlp/\n",
    "import sys \n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgd_nlp.embedding import SkipGram, CorpusFactorySkipGram\n",
    "\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取语料数据\n",
    "def load_corpus(corpus_dir_path, load_obj=False, obj_file_name=None):\n",
    "    \n",
    "    if load_obj and os.path.isfile(obj_file_name):\n",
    "        with open(obj_file_name, 'rb') as fin:\n",
    "            print(\"!!! load corpus factory success !!!\")\n",
    "            return pickle.load(fin)\n",
    "    else:\n",
    "        print('CURRENT PATH:\\t', corpus_dir_path)\n",
    "\n",
    "        corpus_factory = CorpusFactorySkipGram(corpus_dir_path)  # new obj from origin corpus file path\n",
    "        corpus_factory.vocab.log_info()\n",
    "        with open(obj_file_name, 'wb') as fout:\n",
    "            pickle.dump(corpus_factory, fout)\n",
    "        return corpus_factory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(corpus_factory, model, optimizer, scheduler, config):\n",
    "    all_words_num = corpus_factory.vocab.corpus_word_count  # 文档中的总词数\n",
    "    epoch = int(config.corpus_run_loop * all_words_num / config.batch_size)  # 总共需要迭代几个epoch\n",
    "    global_min_loss = 1e6\n",
    "\n",
    "    # training loop\n",
    "    for i in range(epoch):\n",
    "        t1 = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        batch_data = corpus_factory.training_batch(batch_num=config.batch_size,\n",
    "                                                   device=config.device,\n",
    "                                                   win_width=config.win_width,\n",
    "                                                   neg_k=config.neg_k)\n",
    "        y = model.forward(batch_data)\n",
    "\n",
    "        # objective function (loss function)\n",
    "        j_theta = torch.sum(y, dim=[1, 2]).mean()  # maximize objective\n",
    "        nj_theta = -1 * j_theta  # minimize objective\n",
    "\n",
    "        # backward and update weight\n",
    "        nj_theta.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % config.scheduler_step == 0:\n",
    "            scheduler.step()\n",
    "\n",
    "        # output info\n",
    "        tmp_t = time.time() - t1\n",
    "        # avg_time = avg_time * 0.9 + 0.1 * tmp_t\n",
    "        if i % config.log_step == 0:\n",
    "            print('epoch:{}/{}, loss:{}, cost_time: {}'.format(i, epoch, nj_theta, tmp_t))\n",
    "\n",
    "        # save best model\n",
    "        if nj_theta < global_min_loss:\n",
    "            global_min_loss = nj_theta\n",
    "            torch.save(model.state_dict(), config.model_weights_obj_path)\n",
    "            print('new bset loss: {}'.format(nj_theta))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # 文本语料路径\n",
    "    data_home = r'./data'\n",
    "    sub_dir = r'friends/season10'\n",
    "    corpus_dir_path = os.path.join(data_home, sub_dir)\n",
    "    \n",
    "    # 直接加载对象\n",
    "    SAVE_HOME = r'./apps/embedding/save/'\n",
    "    model_name = r'skipgram'\n",
    "    \n",
    "    load_corpus_obj = True # 训练前修改！\n",
    "    corpus_obj_path = os.path.join(SAVE_HOME, model_name, r'corpus_obj.cf') # 加载预处理语料  default:None\n",
    "     \n",
    "    load_model_weight_obj = True # 训练前修改！\n",
    "    model_weights_obj_path = os.path.join(SAVE_HOME, model_name, r'skipgram_weights.path') # 加载预训练模型参数 default:None\n",
    "    \n",
    "    # 语料预处理参数\n",
    "    win_width = 11  # context 窗口大小（前5-中间词-后5）\n",
    "    neg_k = 10  # 负采样数\n",
    "    \n",
    "    # 模型参数\n",
    "    device = torch.device('cuda')\n",
    "    emb_dim = 300\n",
    "    \n",
    "    # 训练参数\n",
    "    lr = 1e-1 # 初始学习率\n",
    "    corpus_run_loop = 2  # 看n遍文本\n",
    "    batch_size = 2048   # 每个batch的大小\n",
    "    scheduler_step = 20\n",
    "    log_step = 50\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app():\n",
    "    # class obj\n",
    "    corpus_factory = load_corpus(corpus_dir_path=config.corpus_dir_path,\n",
    "                                 load_obj=config.load_corpus_obj,\n",
    "                                 obj_file_name=config.corpus_obj_path)\n",
    "    \n",
    "    model = SkipGram(emb_dim = config.emb_dim,\n",
    "                     token_num = corpus_factory.token_num(),\n",
    "                     sparse_emb = True).to(config.device)\n",
    "\n",
    "    # load weight\n",
    "    if config.load_model_weight_obj and os.path.isfile(config.model_weights_obj_path):\n",
    "        model.load_state_dict(torch.load(config.model_weights_obj_path))\n",
    "        print(\"!!! Load model weights success !!!\")\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.SparseAdam(params=model.parameters(), lr=config.lr)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "    train(corpus_factory=corpus_factory,\n",
    "          model=model,\n",
    "          optimizer=optimizer,\n",
    "          scheduler=scheduler,\n",
    "          config=config,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "epoch:0/866, loss:0.3701174259185791, cost_time: 0.1502513885498047\n",
      "new bset loss: 0.3701174259185791\n",
      "new bset loss: 0.2875667214393616\n",
      "new bset loss: 0.0001586870930623263\n",
      "epoch:100/866, loss:19.208141326904297, cost_time: 0.06616735458374023\n",
      "new bset loss: 4.4968953716306714e-07\n",
      "new bset loss: 2.46299508566139e-13\n",
      "epoch:200/866, loss:0.32338595390319824, cost_time: 0.07891416549682617\n",
      "new bset loss: 2.4970805909020142e-17\n",
      "epoch:300/866, loss:10.71897029876709, cost_time: 0.06830739974975586\n",
      "epoch:400/866, loss:0.0521174818277359, cost_time: 0.06322121620178223\n",
      "epoch:500/866, loss:2.894324779510498, cost_time: 0.06169605255126953\n",
      "new bset loss: 1.3585918309745046e-24\n",
      "epoch:600/866, loss:6.7027587890625, cost_time: 0.07483291625976562\n",
      "epoch:700/866, loss:4.0759196281433105, cost_time: 0.08409428596496582\n",
      "epoch:800/866, loss:6.246488094329834, cost_time: 0.06651139259338379\n"
     ]
    }
   ],
   "source": [
    "app()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "res = random.choices([0,1,2,3], weights=[1,1,3,1], k=10)\n",
    "print(type(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
