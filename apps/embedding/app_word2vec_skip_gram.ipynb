{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用训练好的emb来分析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgd_nlp.core.embedding.submodule.corpus_factory import *\n",
    "from sgd_nlp.core.embedding.word2vec import *\n",
    "from sgd_nlp.core.embedding.glove import *\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class glove_context:\n",
    "    corpus_factory= 'save/glove/corpus_obj.cf'\n",
    "    model_path='save/glove/glove_weights.path'\n",
    "    emb_dim = 300\n",
    "    sparse_emb = False\n",
    "    win_width=11\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "\n",
    "class skip_gram_context:\n",
    "    corpus_factory= 'save/skipgram/corpus_obj.cf'\n",
    "    model_path='save/skipgram/skipgram_weights.path'\n",
    "    emb_dim = 300\n",
    "    sparse_emb = True\n",
    "    win_width=11\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "class cbow_context:\n",
    "    corpus_factory= 'save/cbow/corpus_obj.cf'\n",
    "    model_path='save/cbow/cbow_weights.path'\n",
    "    emb_dim = 300\n",
    "    sparse_emb = True\n",
    "    win_width=11\n",
    "    device = torch.device('cuda')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus_factory(obj_file_name):\n",
    "    with open(obj_file_name, 'rb') as fin:\n",
    "        print(\"!!! load corpus factory success !!!\")\n",
    "        return pickle.load(fin)\n",
    "\n",
    "    \n",
    "def load_emb(context):\n",
    "    corpus_factory = load_corpus_factory(context.corpus_factory)\n",
    "    \n",
    "    model = None\n",
    "    if 'skip' in context.model_path:\n",
    "        model = SkipGram(emb_dim=context.emb_dim,\n",
    "                     token_num=corpus_factory.token_num(),\n",
    "                     sparse_emb=context.sparse_emb).to(context.device)\n",
    "    \n",
    "    elif 'cbow' in  context.model_path:\n",
    "        model = Cbow(emb_dim=context.emb_dim,\n",
    "                token_num=corpus_factory.token_num(),\n",
    "                win_width=context.win_width,\n",
    "                sparse_emb=context.sparse_emb).to(context.device)\n",
    "        \n",
    "    elif 'glove' in  context.model_path:\n",
    "        model = Glove(emb_dim=context.emb_dim,\n",
    "                token_num=corpus_factory.token_num(),\n",
    "                sparse_emb=context.sparse_emb).to(context.device)\n",
    "        \n",
    "    model.load_state_dict(torch.load(context.model_path))\n",
    "    print(\"!!! Load model weights success !!!\")\n",
    "    \n",
    "    avg_emb = None\n",
    "    \n",
    "    if 'glove' in context.model_path:\n",
    "        emb_l = model.emb_i.weight\n",
    "        emb_r = model.emb_j.weight\n",
    "        avg_emb = (emb_l+emb_r)/2\n",
    "    \n",
    "    else:\n",
    "        emb_l = model.emb_i.weight\n",
    "        emb_r = model.emb_o.weight\n",
    "        avg_emb = (emb_l+emb_r)/2\n",
    "    \n",
    "    return avg_emb, corpus_factory \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.6650,  5.1770,  0.9831,  ..., -1.3951, -0.8118,  0.3744],\n",
      "        [ 1.6138, -2.2751, -1.0278,  ...,  0.6881, -0.6176,  0.2612],\n",
      "        [-0.9439,  0.4284,  0.1687,  ..., -0.3068,  0.4402,  0.1262],\n",
      "        ...,\n",
      "        [-0.2844,  0.2892, -0.4906,  ...,  0.0661,  0.0971,  0.1666],\n",
      "        [ 0.1695,  0.6495,  0.3074,  ..., -0.2193, -0.6466, -1.4928],\n",
      "        [-0.6326,  0.1975,  0.5403,  ...,  1.4104, -0.5175,  0.1229]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "avg_emb torch.Size([23707, 300])\n",
      "token_num 23697\n",
      "\n",
      "****** VOCAB LOG INFO ******\n",
      "corpus_word_num: 887249\n",
      "vocab_size: 23697\n",
      "word_freq_count: \n",
      "[('the', 26050), ('you', 24618), ('i', 24456), ('to', 19978), ('and', 19046), ('a', 15636), ('it', 9891), ('is', 9517), ('rachel:', 9312), ('ross:', 9226), ('that', 8881), ('chandler:', 8492), ('monica:', 8423), ('joey:', 8332), ('oh', 7807), ('phoebe:', 7527), ('in', 7509), ('of', 7109), ('what', 7025), ('on', 6210), ('this', 6133), ('me', 5762), ('just', 5745), ('no', 5615), ('so', 5598), ('my', 5541), ('with', 5242), ('her', 5139), ('are', 4963), ('yeah', 4944), ('know', 4915), ('okay', 4900), ('have', 4593), ('for', 4583), ('do', 4573), ('we', 4502), ('not', 4464), ('ross', 4359), ('well', 4351), ('he', 4347), ('all', 4163), ('monica', 4128), ('was', 4085), ('chandler', 4074), ('joey', 4073), ('but', 4034), ('up', 4013), ('at', 3979), ('hey', 3969), ('she', 3931)]...\n",
      "...[('implicit', 1), ('plicit', 1), ('cursory', 1), ('protectors', 1), ('cheeseburgers', 1), ('aches', 1), ('hyperventilating', 1), ('assesses', 1), ('1017-1018', 1), ('vo:', 1), ('stomach-aches', 1), ('stomach-ache', 1), ('dracula', 1), ('unanswerable', 1), ('daa', 1), ('raa', 1), ('head-first', 1), ('umbilical', 1), ('spongy', 1), ('reunited', 1), ('bam-bam-bam-bam', 1), ('girl-baby', 1), ('car-service', 1), (\"ethel's\", 1), (\"'40s\", 1), ('gazette', 1), ('continents', 1), (\"cab's\", 1), ('backseat', 1), ('baby-duck', 1), ('infants', 1), ('feces', 1), ('birdcalls', 1), ('woodsman', 1), ('sci-fi', 1), ('life;', 1), ('time-machine', 1), ('death-cab', 1), ('cop-show', 1), ('high-school', 1), ('32c', 1), ('bra-size', 1), ('36d', 1), ('destination', 1), ('flight-number', 1), ('jfk', 1), ('hearing-aids', 1), ('philanges', 1), (\"friggin'\", 1), ('kitchen-counter', 1)]\n",
      "****** vocab log end ******\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(skip_gram_context)\n",
    "print(type(avg_emb))\n",
    "print(avg_emb)\n",
    "print('avg_emb', avg_emb.shape)\n",
    "print('token_num',corpus_factory.vocab.token_num())\n",
    "print()\n",
    "print(corpus_factory.vocab.log_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 老友记6个人的亲密关系排序\n",
    "\n",
    "``` python\n",
    "['monica', 'phoebe', 'rachel', 'joey', 'chandler', 'ross',]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(emb, corpus_factory):\n",
    "    friends = ['monica', 'phoebe', 'rachel', 'joey', 'chandler', 'ross']\n",
    "    friends_id = corpus_factory.vocab[friends]\n",
    "    \n",
    "    friends_emb = emb[friends_id]\n",
    "    \n",
    "    # 计算6个人间的协方差\n",
    "    cov = friends_emb.mm(friends_emb.transpose(0, 1))    \n",
    "    print('\\n emb向量内积')\n",
    "    print(cov)\n",
    "\n",
    "    sort_id = torch.argsort(cov, dim = 1, descending=True)\n",
    "    \n",
    "    print(\"每个人最亲近的关系排序\")\n",
    "    for i in range(6):\n",
    "       \n",
    "        sortid = sort_id[i].tolist()\n",
    "        print([friends[j] for j in sortid])\n",
    "\n",
    "### 找出每个人最相关的top-20的词\n",
    "def find_topk(emb, corpus_factory ,k=20):\n",
    "    friends = ['monica', 'phoebe', 'rachel', 'joey', 'chandler', 'ross']\n",
    "    friends_id = corpus_factory.vocab[friends]\n",
    "    friends_emb = emb[friends_id]\n",
    "    \n",
    "    cov = friends_emb.mm(emb.transpose(0, 1))   # [6, vocab_token_num]\n",
    "    print('\\n emb向量内积')\n",
    "    print(cov)\n",
    "    sort_id = torch.argsort(cov, dim = 1, descending=True)[:, :20]  # [6, 20]\n",
    "\n",
    "    print(\"每个人关系最紧密的topk-20的词\")\n",
    "    for i in range(6):\n",
    "       \n",
    "        sortid = sort_id[i].tolist()\n",
    "        print([corpus_factory.vocab.to_tokens(sortid)])\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "每个人最亲近的关系排序\n",
      "['monica', 'phoebe', 'joey', 'rachel', 'ross', 'chandler']\n",
      "['phoebe', 'monica', 'joey', 'rachel', 'chandler', 'ross']\n",
      "['rachel', 'ross', 'joey', 'monica', 'chandler', 'phoebe']\n",
      "['joey', 'ross', 'monica', 'phoebe', 'rachel', 'chandler']\n",
      "['chandler', 'ross', 'joey', 'monica', 'rachel', 'phoebe']\n",
      "['ross', 'joey', 'rachel', 'chandler', 'monica', 'phoebe']\n",
      "每个人关系最紧密的topk-20的词\n",
      "[['monica', 'mum', 'chiefs', 'vs', 'outisde', 'knockers', 'liam:', 'vais', '20', \"amy's>\", 'oo-oo', \"'fighting'\", 'schoolyard', 'hinges', 'doddle', \"screendon't\", \"a-doin'\", 'tilts', 'provocatively', 'section']]\n",
      "[['phoebe', 'daddy', 'stuart', 'pluck', 'somewhat', 'seasons', 'cheques', 'anybody', \"it'sit's\", 'parrot', 'futile', 'testicles', 'emillio', 'g-go', 'futon', '905', 'duncan', '-make', 'wallet', 'purchased']]\n",
      "[['rachel', 'tratt', 'sally', 'podium', 'suite', '904', 'pirate;', 'blessing', 'mid-term', 'imp', 'owner', 'middle;', 'aggressive', 'oh-whoa-hey', 'rugs', 'your-your', 'centralnot', 'paleontologist:', 'operas', 'cleveland']]\n",
      "[['joey', \"ernie's\", 'fatigues', '25-year-olds', 'hummina-hummina-hummina', '923', \"that'\", 'notakes', 'semi-finals', 'chichas', 'waste', 'fidgeting', 'worm', 'mccreery', 'gut-check', 'furiously', 'expectation', 'shannon', 'anymorrrrre', 'lads']]\n",
      "[['chandler', 'blackout', 'controls', 'pantomimes', 'rooting', 'visitor', 'countanyway', 'phillips', 'yet', 'days', '21', 'lightning-bearer', 'b-a-b-y', 'feelings', 'suppose', 'consult', 'attacks', 'blacked', 'walked', \"two's\"]]\n",
      "[['ross', 'letting', 'punishment', 'jody', 'legislature', 'linguistics', 'staton', 'smelling', \"they'll-they'll\", 'simon', 'bingi', 'untangle', 'lizards', 'orjenga', 'spider', 'wonderfulness', 'benno', 'varoom', \"y'know-y'know\", 'intellectuals']]\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(skip_gram_context)\n",
    "analysis(avg_emb, corpus_factory)\n",
    "find_topk(avg_emb, corpus_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "每个人最亲近的关系排序\n",
      "['monica', 'rachel', 'joey', 'chandler', 'ross', 'phoebe']\n",
      "['phoebe', 'rachel', 'joey', 'chandler', 'monica', 'ross']\n",
      "['rachel', 'phoebe', 'monica', 'ross', 'joey', 'chandler']\n",
      "['joey', 'chandler', 'ross', 'monica', 'phoebe', 'rachel']\n",
      "['chandler', 'joey', 'phoebe', 'monica', 'rachel', 'ross']\n",
      "['ross', 'joey', 'rachel', 'monica', 'chandler', 'phoebe']\n",
      "每个人关系最紧密的topk-20的词\n",
      "[['monica', 'bang', 'frantically', 'petes', 'comforting', 'traipsing', 'mouths', 'deadpan', 'drags', 'screams', '30%', 'erica', 'handing', 'disgust', 'shoves', 'shoulder', 'passionately', 'glaring', 'what-whats', 'th--fun']]\n",
      "[['sr:', 'phoebe', 'poses', 'fear', 'buffay', 'manages', 'joining', ':', 'husband', 'milk', 'cartwheel', 'ewwww', 'knit', 'borkow', 'stabby', 'wrapped', 'mike', 'hodge', 'slept', 'painless']]\n",
      "[['rachel', 'slamming', 'tilts', '123', 'returns', 'amy', 'greep', 'gate', 'dumped', 'strangely', 'mail', \"how're\", 'winks', 'follows', 'hangs', 'punches', 'slowly', 'scaring', 'pushes', 'kisses']]\n",
      "[['tribbiani', 'joey', 'shrugs', 'motions', 'gives', 'avoiding', 'arriving', 'dials', 'torch', 'moves', 'gear', 'buttafucco', 'blah', 'loses', 'gellers', 'searching', 'helping', 'approaches', 'understands', 'drapes']]\n",
      "[['bing', \"eddie's\", 'chandler', 'newspaper', 'faking', 'struts', 'decorated', 'charcoal', 'discuss', 'toward', 'mimics', 'fist', 'managed', 'occupied', 'rice', 'mary', 'colonel:', 'pass', 'hug', 'hide']]\n",
      "[['startling', 'sofa', 'ross', 'lap', 'jokes', 'smiles', 'groans', 'returns', 'notices', 'camera', 'helping', 'lounger', 'near', 'conversation', 'beside', 'regret', 'emily', 'follows', 'amused', 'spider']]\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(cbow_context)\n",
    "analysis(avg_emb, corpus_factory)\n",
    "find_topk(avg_emb, corpus_factory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! load corpus factory success !!!\n",
      "!!! Load model weights success !!!\n",
      "\n",
      " emb向量内积\n",
      "tensor([[0.0117, 0.0072, 0.0075, 0.0051, 0.0071, 0.0063],\n",
      "        [0.0072, 0.0177, 0.0072, 0.0064, 0.0068, 0.0065],\n",
      "        [0.0075, 0.0072, 0.0137, 0.0069, 0.0077, 0.0073],\n",
      "        [0.0051, 0.0064, 0.0069, 0.0096, 0.0059, 0.0067],\n",
      "        [0.0071, 0.0068, 0.0077, 0.0059, 0.0114, 0.0066],\n",
      "        [0.0063, 0.0065, 0.0073, 0.0067, 0.0066, 0.0097]], device='cuda:0',\n",
      "       grad_fn=<MmBackward0>)\n",
      "每个人最亲近的关系排序\n",
      "['monica', 'rachel', 'phoebe', 'chandler', 'ross', 'joey']\n",
      "['phoebe', 'rachel', 'monica', 'chandler', 'ross', 'joey']\n",
      "['rachel', 'chandler', 'monica', 'ross', 'phoebe', 'joey']\n",
      "['joey', 'rachel', 'ross', 'phoebe', 'chandler', 'monica']\n",
      "['chandler', 'rachel', 'monica', 'phoebe', 'ross', 'joey']\n",
      "['ross', 'rachel', 'joey', 'chandler', 'phoebe', 'monica']\n",
      "\n",
      " emb向量内积\n",
      "tensor([[ 0.1195,  0.0043,  0.0049,  ...,  0.0340,  0.0336,  0.1354],\n",
      "        [ 0.1373,  0.0044,  0.0053,  ...,  0.0429,  0.0395, -0.0699],\n",
      "        [ 0.0919,  0.0047,  0.0053,  ...,  0.0874, -0.0182, -0.0279],\n",
      "        [-0.0181,  0.0039,  0.0046,  ...,  0.1372,  0.0366,  0.0203],\n",
      "        [ 0.0142,  0.0042,  0.0049,  ..., -0.0151,  0.0947, -0.0639],\n",
      "        [-0.0310,  0.0043,  0.0050,  ...,  0.0358,  0.0563,  0.0201]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "每个人关系最紧密的topk-20的词\n",
      "[['punctuates', 'accompanies', 'guuuyys', 'troop', 'perverted', 'tracks', 'wowdefinitely', 'night-club', 'ouija', \"co-star's\", 'rejected:', 'impaired', 'truthme', 'silk-screen', 'pff', \"ferry'\", 'injured', 'balled', 'thatokay', 'toute-de-le-fruit']]\n",
      "[['sharpened', 'neighbours', 'weebles', 'tosaltwater', 'heyhey', 'drawers', '7:33', 'thethis', 'indistinctly', 'bearers', 'ricocheted', 'murrays', 'loaf', 'portuguese', \"'fighting'\", 'whiny', 'real-estate', 'wooo', 'typingwhat', '2300']]\n",
      "[[\"joanna's\", 'tracks', \"fly's\", 'mopeds', 'labour', 'semen', 'pinning', 'witnessed', 'pressurised', 'iswho', '98', \"why're\", 'wa-', 'umyou', 'book:', 'dirtier', 'pff', 'think;', \"m'ap\", 'candys']]\n",
      "[['edward', 'sharpened', 'tart', 'torts', \"idiot'\", 'keeping', 'kn-i', 'shhhi', 'declarations', 'accompanies', 'israel', 'sun-dried', 'brave', 'fitch', 'romance', 'tracks', \"perfection'\", 'celia', 'ross-joey', 'intercept']]\n",
      "[['torts', 'hurridly', 'canclose', 'tart', 'millionaire', \"fly's\", \"ferry'\", \"idiot'\", 'spelling', 'dreaming', 'dirtier', \"can'tyou\", 'troop', 'declarations', 'sun-dried', 'grazie', \"joanna's\", 'countdownengineson', 'buffays', 'tapdance']]\n",
      "[[\"joanna's\", 'kn-i', 'whiny', 'fitch', 'dont-i', 'tracks', 'decorated', 'gains', 'justyknowi-i', \"idiot'\", 'torts', 'umyou', 'quilt', 'cheerfully', '605:', \"sat's\", 'frantic', 'exposed', '98', 'giants-cowboys']]\n"
     ]
    }
   ],
   "source": [
    "avg_emb, corpus_factory = load_emb(glove_context)\n",
    "analysis(avg_emb, corpus_factory)\n",
    "find_topk(avg_emb, corpus_factory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果分析\n",
    "[结果分析.txt](./%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90.txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea68e26e2ec5512da56afdae1ccbc3f0c30917ed34c855b0cd4787221c3f6afe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
