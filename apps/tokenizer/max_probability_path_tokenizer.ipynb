{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大概率路径分词-基于字典统计的概率分词模型\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "基于一阶语言模型的概率分词(最大化分词路径的概率)\n",
    "\n",
    "method:\n",
    "    1、基于trie tree构建待分词句子的所有分词路径(图结构)\n",
    "    2、train:统计训练样本中词转移概率\n",
    "    3、inference:返回最大概率的分词路径\n",
    "\n",
    "注：类似jieba分词\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/sgd_deep_learning/sgd_nlp\n"
     ]
    }
   ],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_nlp/\n",
    "import sys \n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgd_nlp.tokenizer import MaxProbabilityPathTokenizer\n",
    "from sgd_nlp.common import yield_tokens_list\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['唯一', '打破', '这', '一', '岑寂', '的', '是', '这里', '的', '山泉', '。'], -239.46884967138084)\n",
      "(['工', '信', '处女', '干事', '每月', '经过', '下属', '科室', '都', '要', '亲口', '交代', '2', '4', '口', '交换机', '等', '技术性', '器件', '的', '安装', '工作'], -442.09633785485664)\n",
      "(['多年来', ',', '中', '希', '贸易', '始终', '处于', '较低', '的', '水平', ',', '希腊', '几乎', '没有', '在', '中国', '投资', '。'], -368.41361487904726)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# simple test code\n",
    "data_home = r\"./data\"\n",
    "dir_path = r\"tokenizer/backoff2005/training\"\n",
    "train_file = \"msr_training.utf8\"\n",
    "training_file_path = os.path.join(data_home, dir_path, train_file)\n",
    "\n",
    "# training data\n",
    "training_tokens_list = yield_tokens_list(training_file_path, encoding='utf-8')\n",
    "# model\n",
    "tokenizers = MaxProbabilityPathTokenizer()\n",
    "\n",
    "# train and inference\n",
    "tokenizers.clear()\n",
    "tokenizers.train(training_tokens_list)\n",
    "\n",
    "# inference\n",
    "test_seq1 = r'唯一打破这一岑寂的是这里的山泉。'\n",
    "test_seq2 = r'工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作'\n",
    "test_seq3 = r'多年来,中希贸易始终处于较低的水平,希腊几乎没有在中国投资。'\n",
    "\n",
    "print(tokenizers.inference(test_seq1))\n",
    "print(tokenizers.inference(test_seq2))\n",
    "print(tokenizers.inference(test_seq3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
