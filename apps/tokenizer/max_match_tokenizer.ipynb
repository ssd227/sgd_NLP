{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于字典的最大匹配分词\n",
    "\n",
    "原理:\n",
    "    对于给定待分词语料，每个句子按照词典最大匹配的结果 分割语料并返回结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/playground/sgd_deep_learning/sgd_nlp\n"
     ]
    }
   ],
   "source": [
    "# 环境配置\n",
    "%cd /playground/sgd_deep_learning/sgd_nlp/\n",
    "import sys \n",
    "sys.path.append('./python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sgd_nlp.tokenizer import MaxMatchTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*--**--**--**--**--**--**--**--**--**--*\n",
      "原句子:\t 我是周杰伦，唱一首七里香\n",
      "分词结果:\t ['我', '是', '周杰伦', '，', '唱', '一首', '七里香']\n",
      "逆序分词结果:\t ['我', '是', '周杰伦', '，', '唱', '一首', '七里香']\n",
      "\n",
      "*--**--**--**--**--**--**--**--**--**--*\n",
      "原句子:\t 工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作\n",
      "分词结果:\t ['工信处', '女干事', '每月', '经过', '下属', '科室', '都要', '亲口', '交代', '24', '口交', '换', '机', '等', '技术性', '器件', '的', '安装', '工作']\n",
      "逆序分词结果:\t ['工信处', '女干事', '每月', '经过', '下属', '科室', '都要', '亲口', '交代', '24', '口', '交换机', '等', '技术性', '器件', '的', '安装', '工作']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_home = r\"./data\"\n",
    "sub_dir = 'tokenizer/dicts'\n",
    "dict_name = 'test_default_dict'\n",
    "dpath = os.path.join(data_home, sub_dir, dict_name)\n",
    "\n",
    "tokenizer = MaxMatchTokenizer(dict_path=dpath, seq_reverse=False)\n",
    "tokenizer_reverse = MaxMatchTokenizer(dict_path=dpath, seq_reverse=True)\n",
    "\n",
    "seq1 = '我是周杰伦，唱一首七里香'\n",
    "seq2 = '工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作'\n",
    "\n",
    "def test_tokenizer(seq):\n",
    "    res = tokenizer.forward(seq)\n",
    "    reverse_res = tokenizer_reverse.forward(seq)\n",
    "\n",
    "    print('*--*'*10)\n",
    "    print('原句子:\\t', seq)\n",
    "    print('分词结果:\\t', res)\n",
    "    print('逆序分词结果:\\t', reverse_res, end='\\n'*2)\n",
    "\n",
    "test_tokenizer(seq1)\n",
    "test_tokenizer(seq2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
